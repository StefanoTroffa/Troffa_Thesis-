{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "This tutorial builds a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>, following the tensorflow tutorial to have a term of comparison. The performance of the quantum neural network and the graph version on this classical data problem is compared with a classical neural network. After tons of trial I was not able to train a Graph Neural Network on the Mnist reduced dataset 4x4 for binary classification of digits 3 and 6. Further study of the architecture is needed to figure out what is going wrong and why.  I observed difference in performance betweeen the Quantum Neural Network with input data given as single rotation on each qubit and an input data that takes into account some fixed rotation on qubit pairs following the adjacency matrix. The two Quantum Neural Network have further learned different parameters as expected. The accuracy seems slightly higher when taking into account the adjacency matrix for the input data, however the training time also increase considerably. However, it should be notice that in this case study the network number of gates is comparable to the input data number of gates, hence for much deeper network we expect the slow down to be negligible.\n",
    "The classical Neural Network outperforms the quantum ones, however it was trained for more epochs, regardless the accuracy tops around 92% and does not seem to be able to grow further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "At the present moment, there is no yet a standardized procedure to find the best ***learning rate***, we want to implement a Tuner (maybe the one from tensorflow, even better if I can code my own) to find the optimal learning rate, followed with a cyclic learning rate routine, as implemented by <a href=\"https://arxiv.org/abs/1506.01186\" class=\"external\">Leslie N. Smith</a>, in 2015. The procedure is ordinarely used in the Deep Learning community, and I am interested in proving that also in this data provides better results compared to constant, exponentially decreasing and linear decreasing learning rate.\n",
    "\n",
    "For what it regards the ***batch size*** we found the result from <a href=\"https://openreview.net/pdf?id=B1Yy1BxCZ\" class=\"external\">Samuel L. Smith, Pieter-Jan Kindermans, Chris Ying & Quoc V. Le </a>, they have shown that increasing the batch size provides similar results to decreasing the learning rate but has fewer parameters updates. If it suitable we will try to see if that holds also in training Quantum Neural Networks and (eventually) if it is more or less robust to small noise in data\n",
    "\n",
    "Turning to ***metrics & loss functions***, I have yet to build a better understanding of the different possibilities and how they influence the training, both in quantum and classical neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility of the current work:\n",
    "\n",
    "I have developed a better understanding of the syntax and standard procedures in Machine Learning, I was able to work effectively with TensorflowQuantum and I know how to setup different conda environment to avoid conflicts between packages. \n",
    "I was able to extract from data that has not an inherent graph structure an adjacency matrix and use it for training the Quantum Neural Network. Further research on the classical graph neural network however is needed. I am starting to work on a different dataset, namely the Ising Model 5x5 as last part of playing around. Afterwords, I will deal with Ising Chains and Heisenberg Model. For now we are sticking to classification tasks, therefore the protein datasets might be dealt with next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:42.735851Z",
     "iopub.status.busy": "2023-03-21T11:34:42.735242Z",
     "iopub.status.idle": "2023-03-21T11:34:46.481506Z",
     "shell.execute_reply": "2023-03-21T11:34:46.480608Z"
    },
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
    "\n",
    "- Loads the raw data from Keras.\n",
    "- Filters the dataset to only 3s and 6s.\n",
    "- Downscales the images so they fit can fit in a quantum computer.\n",
    "- Removes any contradictory examples.\n",
    "- Converts the binary images to Cirq circuits.\n",
    "- Converts the Cirq circuits to TensorFlow Quantum circuits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:46.486372Z",
     "iopub.status.busy": "2023-03-21T11:34:46.484926Z",
     "iopub.status.idle": "2023-03-21T11:34:47.121710Z",
     "shell.execute_reply": "2023-03-21T11:34:47.120913Z"
    },
    "id": "d9OSExvCojg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZpbygdGojg3"
   },
   "source": [
    "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.125227Z",
     "iopub.status.busy": "2023-03-21T11:34:47.124647Z",
     "iopub.status.idle": "2023-03-21T11:34:47.128767Z",
     "shell.execute_reply": "2023-03-21T11:34:47.128094Z"
    },
    "id": "hOw68cCZojg4"
   },
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.131737Z",
     "iopub.status.busy": "2023-03-21T11:34:47.131279Z",
     "iopub.status.idle": "2023-03-21T11:34:47.172507Z",
     "shell.execute_reply": "2023-03-21T11:34:47.171720Z"
    },
    "id": "p-XEU8egGL6q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wyiaP0Xojg_"
   },
   "source": [
    "Show the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.176062Z",
     "iopub.status.busy": "2023-03-21T11:34:47.175515Z",
     "iopub.status.idle": "2023-03-21T11:34:47.482701Z",
     "shell.execute_reply": "2023-03-21T11:34:47.481778Z"
    },
    "id": "j5STP7MbojhA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 Downscale the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.486559Z",
     "iopub.status.busy": "2023-03-21T11:34:47.485823Z",
     "iopub.status.idle": "2023-03-21T11:34:47.583288Z",
     "shell.execute_reply": "2023-03-21T11:34:47.582349Z"
    },
    "id": "lbhUdBFWojhE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rescale_l=4\n",
    "\n",
    "x_train_small = tf.image.resize(x_train, (rescale_l,rescale_l)).numpy()\n",
    "x_test_small = tf.image.resize(x_test, (rescale_l,rescale_l)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training exampleâ€”after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.587071Z",
     "iopub.status.busy": "2023-03-21T11:34:47.586363Z",
     "iopub.status.idle": "2023-03-21T11:34:47.858444Z",
     "shell.execute_reply": "2023-03-21T11:34:47.857517Z"
    },
    "id": "YIYOtCRIGL6y",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGeF1_qtojhK"
   },
   "source": [
    "### 1.3 Remove contradictory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZLkq2yeojhL"
   },
   "source": [
    "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
    "\n",
    "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.862246Z",
     "iopub.status.busy": "2023-03-21T11:34:47.861552Z",
     "iopub.status.idle": "2023-03-21T11:34:47.870209Z",
     "shell.execute_reply": "2023-03-21T11:34:47.869326Z"
    },
    "id": "LqOPW0C7ojhL"
   },
   "outputs": [],
   "source": [
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    orig_x = {}\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "        orig_x[tuple(x.flatten())] = x\n",
    "        mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for flatten_x in mapping:\n",
    "        x = orig_x[flatten_x]\n",
    "        labels = mapping[flatten_x]\n",
    "        if len(labels) == 1:\n",
    "            new_x.append(x)\n",
    "            new_y.append(next(iter(labels)))\n",
    "        else:\n",
    "            # Throw out images that match more than one label.\n",
    "            pass\n",
    "    \n",
    "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
    "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
    "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of unique 3s: \", num_uniq_3)\n",
    "    print(\"Number of unique 6s: \", num_uniq_6)\n",
    "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
    "    print()\n",
    "    print(\"Initial number of images: \", len(xs))\n",
    "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMOiJfz_ojhP"
   },
   "source": [
    "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
    "\n",
    "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:47.873282Z",
     "iopub.status.busy": "2023-03-21T11:34:47.872807Z",
     "iopub.status.idle": "2023-03-21T11:34:48.013719Z",
     "shell.execute_reply": "2023-03-21T11:34:48.012747Z"
    },
    "id": "zpnsAssWojhP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 10387\n",
      "Number of unique 3s:  4912\n",
      "Number of unique 6s:  5426\n",
      "Number of unique contradicting labels (both 3 and 6):  49\n",
      "\n",
      "Initial number of images:  12049\n",
      "Remaining non-contradicting unique images:  10338\n"
     ]
    }
   ],
   "source": [
    "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhT"
   },
   "source": [
    "### 1.4 Encode the data as quantum circuits\n",
    "\n",
    "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel. The first step is to convert to a binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:48.017334Z",
     "iopub.status.busy": "2023-03-21T11:34:48.016608Z",
     "iopub.status.idle": "2023-03-21T11:34:48.021725Z",
     "shell.execute_reply": "2023-03-21T11:34:48.020835Z"
    },
    "id": "1z8J7OyDojhV"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhU"
   },
   "source": [
    "If you were to remove contradictory images at this point you would be left with only 193, likely not enough for effective training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:48.025059Z",
     "iopub.status.busy": "2023-03-21T11:34:48.024374Z",
     "iopub.status.idle": "2023-03-21T11:34:48.096023Z",
     "shell.execute_reply": "2023-03-21T11:34:48.095146Z"
    },
    "id": "1z8J7OyDojhW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 193\n",
      "Number of unique 3s:  80\n",
      "Number of unique 6s:  69\n",
      "Number of unique contradicting labels (both 3 and 6):  44\n",
      "\n",
      "Initial number of images:  10338\n",
      "Remaining non-contradicting unique images:  149\n"
     ]
    }
   ],
   "source": [
    "_ = remove_contradicting(x_train_bin, y_train_nocon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLyxS9KlojhZ"
   },
   "source": [
    "The qubits at pixel indices with values that exceed a threshold, are rotated through an $X$ gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:48.099500Z",
     "iopub.status.busy": "2023-03-21T11:34:48.099001Z",
     "iopub.status.idle": "2023-03-21T11:34:50.313236Z",
     "shell.execute_reply": "2023-03-21T11:34:50.312427Z"
    },
    "id": "aOu_3-3ZGL61"
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "            \n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
    "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSCXqzOzojhd"
   },
   "source": [
    "Here is the circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module matplotlib.font_manager in matplotlib:\n",
      "\n",
      "NAME\n",
      "    matplotlib.font_manager - A module for finding, managing, and using fonts across platforms.\n",
      "\n",
      "DESCRIPTION\n",
      "    This module provides a single `FontManager` instance, ``fontManager``, that can\n",
      "    be shared across backends and platforms.  The `findfont`\n",
      "    function returns the best TrueType (TTF) font file in the local or\n",
      "    system font path that matches the specified `FontProperties`\n",
      "    instance.  The `FontManager` also handles Adobe Font Metrics\n",
      "    (AFM) font files for use by the PostScript backend.\n",
      "    \n",
      "    The design is based on the `W3C Cascading Style Sheet, Level 1 (CSS1)\n",
      "    font specification <http://www.w3.org/TR/1998/REC-CSS2-19980512/>`_.\n",
      "    Future versions may implement the Level 2 or 2.1 specifications.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        FontManager\n",
      "        FontProperties\n",
      "    \n",
      "    class FontManager(builtins.object)\n",
      "     |  FontManager(size=None, weight='normal')\n",
      "     |  \n",
      "     |  On import, the `FontManager` singleton instance creates a list of ttf and\n",
      "     |  afm fonts and caches their `FontProperties`.  The `FontManager.findfont`\n",
      "     |  method does a nearest neighbor search to find the font that most closely\n",
      "     |  matches the specification.  If no good enough match is found, the default\n",
      "     |  font is returned.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, size=None, weight='normal')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  addfont(self, path)\n",
      "     |      Cache the properties of the font at *path* to make it available to the\n",
      "     |      `FontManager`.  The type of font is inferred from the path suffix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str or path-like\n",
      "     |  \n",
      "     |  findfont(self, prop, fontext='ttf', directory=None, fallback_to_default=True, rebuild_if_missing=True)\n",
      "     |      Find a font that most closely matches the given font properties.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      prop : str or `~matplotlib.font_manager.FontProperties`\n",
      "     |          The font properties to search for. This can be either a\n",
      "     |          `.FontProperties` object or a string defining a\n",
      "     |          `fontconfig patterns`_.\n",
      "     |      \n",
      "     |      fontext : {'ttf', 'afm'}, default: 'ttf'\n",
      "     |          The extension of the font file:\n",
      "     |      \n",
      "     |          - 'ttf': TrueType and OpenType fonts (.ttf, .ttc, .otf)\n",
      "     |          - 'afm': Adobe Font Metrics (.afm)\n",
      "     |      \n",
      "     |      directory : str, optional\n",
      "     |          If given, only search this directory and its subdirectories.\n",
      "     |      \n",
      "     |      fallback_to_default : bool\n",
      "     |          If True, will fall back to the default font family (usually\n",
      "     |          \"DejaVu Sans\" or \"Helvetica\") if the first lookup hard-fails.\n",
      "     |      \n",
      "     |      rebuild_if_missing : bool\n",
      "     |          Whether to rebuild the font cache and search again if the first\n",
      "     |          match appears to point to a nonexisting font (i.e., the font cache\n",
      "     |          contains outdated entries).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          The filename of the best matching font.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This performs a nearest neighbor search.  Each font is given a\n",
      "     |      similarity score to the target font properties.  The first font with\n",
      "     |      the highest score is returned.  If no matches below a certain\n",
      "     |      threshold are found, the default font (usually DejaVu Sans) is\n",
      "     |      returned.\n",
      "     |      \n",
      "     |      The result is cached, so subsequent lookups don't have to\n",
      "     |      perform the O(n) nearest neighbor search.\n",
      "     |      \n",
      "     |      See the `W3C Cascading Style Sheet, Level 1\n",
      "     |      <http://www.w3.org/TR/1998/REC-CSS2-19980512/>`_ documentation\n",
      "     |      for a description of the font finding algorithm.\n",
      "     |      \n",
      "     |      .. _fontconfig patterns:\n",
      "     |         https://www.freedesktop.org/software/fontconfig/fontconfig-user.html\n",
      "     |  \n",
      "     |  get_default_weight(self)\n",
      "     |      Return the default font weight.\n",
      "     |  \n",
      "     |  get_font_names(self)\n",
      "     |      Return the list of available fonts.\n",
      "     |  \n",
      "     |  score_family(self, families, family2)\n",
      "     |      Return a match score between the list of font families in\n",
      "     |      *families* and the font family name *family2*.\n",
      "     |      \n",
      "     |      An exact match at the head of the list returns 0.0.\n",
      "     |      \n",
      "     |      A match further down the list will return between 0 and 1.\n",
      "     |      \n",
      "     |      No match will return 1.0.\n",
      "     |  \n",
      "     |  score_size(self, size1, size2)\n",
      "     |      Return a match score between *size1* and *size2*.\n",
      "     |      \n",
      "     |      If *size2* (the size specified in the font file) is 'scalable', this\n",
      "     |      function always returns 0.0, since any font size can be generated.\n",
      "     |      \n",
      "     |      Otherwise, the result is the absolute distance between *size1* and\n",
      "     |      *size2*, normalized so that the usual range of font sizes (6pt -\n",
      "     |      72pt) will lie between 0.0 and 1.0.\n",
      "     |  \n",
      "     |  score_stretch(self, stretch1, stretch2)\n",
      "     |      Return a match score between *stretch1* and *stretch2*.\n",
      "     |      \n",
      "     |      The result is the absolute value of the difference between the\n",
      "     |      CSS numeric values of *stretch1* and *stretch2*, normalized\n",
      "     |      between 0.0 and 1.0.\n",
      "     |  \n",
      "     |  score_style(self, style1, style2)\n",
      "     |      Return a match score between *style1* and *style2*.\n",
      "     |      \n",
      "     |      An exact match returns 0.0.\n",
      "     |      \n",
      "     |      A match between 'italic' and 'oblique' returns 0.1.\n",
      "     |      \n",
      "     |      No match returns 1.0.\n",
      "     |  \n",
      "     |  score_variant(self, variant1, variant2)\n",
      "     |      Return a match score between *variant1* and *variant2*.\n",
      "     |      \n",
      "     |      An exact match returns 0.0, otherwise 1.0.\n",
      "     |  \n",
      "     |  score_weight(self, weight1, weight2)\n",
      "     |      Return a match score between *weight1* and *weight2*.\n",
      "     |      \n",
      "     |      The result is 0.0 if both weight1 and weight 2 are given as strings\n",
      "     |      and have the same value.\n",
      "     |      \n",
      "     |      Otherwise, the result is the absolute value of the difference between\n",
      "     |      the CSS numeric values of *weight1* and *weight2*, normalized between\n",
      "     |      0.05 and 1.0.\n",
      "     |  \n",
      "     |  set_default_weight(self, weight)\n",
      "     |      Set the default font weight.  The initial value is 'normal'.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  get_default_size()\n",
      "     |      Return the default font size.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  defaultFont\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FontProperties(builtins.object)\n",
      "     |  FontProperties(family=None, style=None, variant=None, weight=None, stretch=None, size=None, fname=None, math_fontfamily=None)\n",
      "     |  \n",
      "     |  A class for storing and manipulating font properties.\n",
      "     |  \n",
      "     |  The font properties are the six properties described in the\n",
      "     |  `W3C Cascading Style Sheet, Level 1\n",
      "     |  <http://www.w3.org/TR/1998/REC-CSS2-19980512/>`_ font\n",
      "     |  specification and *math_fontfamily* for math fonts:\n",
      "     |  \n",
      "     |  - family: A list of font names in decreasing order of priority.\n",
      "     |    The items may include a generic font family name, either 'sans-serif',\n",
      "     |    'serif', 'cursive', 'fantasy', or 'monospace'.  In that case, the actual\n",
      "     |    font to be used will be looked up from the associated rcParam during the\n",
      "     |    search process in `.findfont`. Default: :rc:`font.family`\n",
      "     |  \n",
      "     |  - style: Either 'normal', 'italic' or 'oblique'.\n",
      "     |    Default: :rc:`font.style`\n",
      "     |  \n",
      "     |  - variant: Either 'normal' or 'small-caps'.\n",
      "     |    Default: :rc:`font.variant`\n",
      "     |  \n",
      "     |  - stretch: A numeric value in the range 0-1000 or one of\n",
      "     |    'ultra-condensed', 'extra-condensed', 'condensed',\n",
      "     |    'semi-condensed', 'normal', 'semi-expanded', 'expanded',\n",
      "     |    'extra-expanded' or 'ultra-expanded'. Default: :rc:`font.stretch`\n",
      "     |  \n",
      "     |  - weight: A numeric value in the range 0-1000 or one of\n",
      "     |    'ultralight', 'light', 'normal', 'regular', 'book', 'medium',\n",
      "     |    'roman', 'semibold', 'demibold', 'demi', 'bold', 'heavy',\n",
      "     |    'extra bold', 'black'. Default: :rc:`font.weight`\n",
      "     |  \n",
      "     |  - size: Either a relative value of 'xx-small', 'x-small',\n",
      "     |    'small', 'medium', 'large', 'x-large', 'xx-large' or an\n",
      "     |    absolute font size, e.g., 10. Default: :rc:`font.size`\n",
      "     |  \n",
      "     |  - math_fontfamily: The family of fonts used to render math text.\n",
      "     |    Supported values are: 'dejavusans', 'dejavuserif', 'cm',\n",
      "     |    'stix', 'stixsans' and 'custom'. Default: :rc:`mathtext.fontset`\n",
      "     |  \n",
      "     |  Alternatively, a font may be specified using the absolute path to a font\n",
      "     |  file, by using the *fname* kwarg.  However, in this case, it is typically\n",
      "     |  simpler to just pass the path (as a `pathlib.Path`, not a `str`) to the\n",
      "     |  *font* kwarg of the `.Text` object.\n",
      "     |  \n",
      "     |  The preferred usage of font sizes is to use the relative values,\n",
      "     |  e.g.,  'large', instead of absolute font sizes, e.g., 12.  This\n",
      "     |  approach allows all text sizes to be made larger or smaller based\n",
      "     |  on the font manager's default font size.\n",
      "     |  \n",
      "     |  This class will also accept a fontconfig_ pattern_, if it is the only\n",
      "     |  argument provided.  This support does not depend on fontconfig; we are\n",
      "     |  merely borrowing its pattern syntax for use here.\n",
      "     |  \n",
      "     |  .. _fontconfig: https://www.freedesktop.org/wiki/Software/fontconfig/\n",
      "     |  .. _pattern:\n",
      "     |     https://www.freedesktop.org/software/fontconfig/fontconfig-user.html\n",
      "     |  \n",
      "     |  Note that Matplotlib's internal font manager and fontconfig use a\n",
      "     |  different algorithm to lookup fonts, so the results of the same pattern\n",
      "     |  may be different in Matplotlib than in other applications that use\n",
      "     |  fontconfig.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, family=None, style=None, variant=None, weight=None, stretch=None, size=None, fname=None, math_fontfamily=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  copy(self)\n",
      "     |      Return a copy of self.\n",
      "     |  \n",
      "     |  get_family(self)\n",
      "     |      Return a list of individual font family names or generic family names.\n",
      "     |      \n",
      "     |      The font families or generic font families (which will be resolved\n",
      "     |      from their respective rcParams when searching for a matching font) in\n",
      "     |      the order of preference.\n",
      "     |  \n",
      "     |  get_file(self)\n",
      "     |      Return the filename of the associated font.\n",
      "     |  \n",
      "     |  get_fontconfig_pattern(self)\n",
      "     |      Get a fontconfig_ pattern_ suitable for looking up the font as\n",
      "     |      specified with fontconfig's ``fc-match`` utility.\n",
      "     |      \n",
      "     |      This support does not depend on fontconfig; we are merely borrowing its\n",
      "     |      pattern syntax for use here.\n",
      "     |  \n",
      "     |  get_math_fontfamily(self)\n",
      "     |      Return the name of the font family used for math text.\n",
      "     |      \n",
      "     |      The default font is :rc:`mathtext.fontset`.\n",
      "     |  \n",
      "     |  get_name(self)\n",
      "     |      Return the name of the font that best matches the font properties.\n",
      "     |  \n",
      "     |  get_size(self)\n",
      "     |      Return the font size.\n",
      "     |  \n",
      "     |  get_size_in_points = get_size(self)\n",
      "     |  \n",
      "     |  get_slant = get_style(self)\n",
      "     |  \n",
      "     |  get_stretch(self)\n",
      "     |      Return the font stretch or width.  Options are: 'ultra-condensed',\n",
      "     |      'extra-condensed', 'condensed', 'semi-condensed', 'normal',\n",
      "     |      'semi-expanded', 'expanded', 'extra-expanded', 'ultra-expanded'.\n",
      "     |  \n",
      "     |  get_style(self)\n",
      "     |      Return the font style.  Values are: 'normal', 'italic' or 'oblique'.\n",
      "     |  \n",
      "     |  get_variant(self)\n",
      "     |      Return the font variant.  Values are: 'normal' or 'small-caps'.\n",
      "     |  \n",
      "     |  get_weight(self)\n",
      "     |      Set the font weight.  Options are: A numeric value in the\n",
      "     |      range 0-1000 or one of 'light', 'normal', 'regular', 'book',\n",
      "     |      'medium', 'roman', 'semibold', 'demibold', 'demi', 'bold',\n",
      "     |      'heavy', 'extra bold', 'black'\n",
      "     |  \n",
      "     |  set_family(self, family)\n",
      "     |      Change the font family.  Can be either an alias (generic name\n",
      "     |      is CSS parlance), such as: 'serif', 'sans-serif', 'cursive',\n",
      "     |      'fantasy', or 'monospace', a real font name or a list of real\n",
      "     |      font names.  Real font names are not supported when\n",
      "     |      :rc:`text.usetex` is `True`. Default: :rc:`font.family`\n",
      "     |  \n",
      "     |  set_file(self, file)\n",
      "     |      Set the filename of the fontfile to use.  In this case, all\n",
      "     |      other properties will be ignored.\n",
      "     |  \n",
      "     |  set_fontconfig_pattern(self, pattern)\n",
      "     |      Set the properties by parsing a fontconfig_ *pattern*.\n",
      "     |      \n",
      "     |      This support does not depend on fontconfig; we are merely borrowing its\n",
      "     |      pattern syntax for use here.\n",
      "     |  \n",
      "     |  set_math_fontfamily(self, fontfamily)\n",
      "     |      Set the font family for text in math mode.\n",
      "     |      \n",
      "     |      If not set explicitly, :rc:`mathtext.fontset` will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fontfamily : str\n",
      "     |          The name of the font family.\n",
      "     |      \n",
      "     |          Available font families are defined in the\n",
      "     |          matplotlibrc.template file\n",
      "     |          :ref:`here <customizing-with-matplotlibrc-files>`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .text.Text.get_math_fontfamily\n",
      "     |  \n",
      "     |  set_name = set_family(self, family)\n",
      "     |  \n",
      "     |  set_size(self, size)\n",
      "     |      Set the font size.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : float or {'xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large'}, default: :rc:`font.size`\n",
      "     |          If a float, the font size in points. The string values denote\n",
      "     |          sizes relative to the default font size.\n",
      "     |  \n",
      "     |  set_slant = set_style(self, style)\n",
      "     |  \n",
      "     |  set_stretch(self, stretch)\n",
      "     |      Set the font stretch or width.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stretch : int or {'ultra-condensed', 'extra-condensed', 'condensed', 'semi-condensed', 'normal', 'semi-expanded', 'expanded', 'extra-expanded', 'ultra-expanded'}, default: :rc:`font.stretch`\n",
      "     |          If int, must be in the range  0-1000.\n",
      "     |  \n",
      "     |  set_style(self, style)\n",
      "     |      Set the font style.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      style : {'normal', 'italic', 'oblique'}, default: :rc:`font.style`\n",
      "     |  \n",
      "     |  set_variant(self, variant)\n",
      "     |      Set the font variant.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      variant : {'normal', 'small-caps'}, default: :rc:`font.variant`\n",
      "     |  \n",
      "     |  set_weight(self, weight)\n",
      "     |      Set the font weight.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      weight : int or {'ultralight', 'light', 'normal', 'regular', 'book', 'medium', 'roman', 'semibold', 'demibold', 'demi', 'bold', 'heavy', 'extra bold', 'black'}, default: :rc:`font.weight`\n",
      "     |          If int, must be in the range  0-1000.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __slotnames__ = []\n",
      "\n",
      "FUNCTIONS\n",
      "    afmFontProperty(fontpath, font)\n",
      "        Extract information from an AFM font file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        font : AFM\n",
      "            The AFM font file from which information will be extracted.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        `FontEntry`\n",
      "            The extracted font properties.\n",
      "    \n",
      "    findSystemFonts(fontpaths=None, fontext='ttf')\n",
      "        Search for fonts in the specified font paths.  If no paths are\n",
      "        given, will use a standard set of system paths, as well as the\n",
      "        list of fonts tracked by fontconfig if fontconfig is installed and\n",
      "        available.  A list of TrueType fonts are returned by default with\n",
      "        AFM fonts as an option.\n",
      "    \n",
      "    findfont(prop, fontext='ttf', directory=None, fallback_to_default=True, rebuild_if_missing=True) method of FontManager instance\n",
      "        Find a font that most closely matches the given font properties.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        prop : str or `~matplotlib.font_manager.FontProperties`\n",
      "            The font properties to search for. This can be either a\n",
      "            `.FontProperties` object or a string defining a\n",
      "            `fontconfig patterns`_.\n",
      "        \n",
      "        fontext : {'ttf', 'afm'}, default: 'ttf'\n",
      "            The extension of the font file:\n",
      "        \n",
      "            - 'ttf': TrueType and OpenType fonts (.ttf, .ttc, .otf)\n",
      "            - 'afm': Adobe Font Metrics (.afm)\n",
      "        \n",
      "        directory : str, optional\n",
      "            If given, only search this directory and its subdirectories.\n",
      "        \n",
      "        fallback_to_default : bool\n",
      "            If True, will fall back to the default font family (usually\n",
      "            \"DejaVu Sans\" or \"Helvetica\") if the first lookup hard-fails.\n",
      "        \n",
      "        rebuild_if_missing : bool\n",
      "            Whether to rebuild the font cache and search again if the first\n",
      "            match appears to point to a nonexisting font (i.e., the font cache\n",
      "            contains outdated entries).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        str\n",
      "            The filename of the best matching font.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This performs a nearest neighbor search.  Each font is given a\n",
      "        similarity score to the target font properties.  The first font with\n",
      "        the highest score is returned.  If no matches below a certain\n",
      "        threshold are found, the default font (usually DejaVu Sans) is\n",
      "        returned.\n",
      "        \n",
      "        The result is cached, so subsequent lookups don't have to\n",
      "        perform the O(n) nearest neighbor search.\n",
      "        \n",
      "        See the `W3C Cascading Style Sheet, Level 1\n",
      "        <http://www.w3.org/TR/1998/REC-CSS2-19980512/>`_ documentation\n",
      "        for a description of the font finding algorithm.\n",
      "        \n",
      "        .. _fontconfig patterns:\n",
      "           https://www.freedesktop.org/software/fontconfig/fontconfig-user.html\n",
      "    \n",
      "    get_font(font_filepaths, hinting_factor=None)\n",
      "        Get an `.ft2font.FT2Font` object given a list of file paths.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        font_filepaths : Iterable[str, Path, bytes], str, Path, bytes\n",
      "            Relative or absolute paths to the font files to be used.\n",
      "        \n",
      "            If a single string, bytes, or `pathlib.Path`, then it will be treated\n",
      "            as a list with that entry only.\n",
      "        \n",
      "            If more than one filepath is passed, then the returned FT2Font object\n",
      "            will fall back through the fonts, in the order given, to find a needed\n",
      "            glyph.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        `.ft2font.FT2Font`\n",
      "    \n",
      "    get_font_names() method of FontManager instance\n",
      "        Return the list of available fonts.\n",
      "    \n",
      "    get_fontext_synonyms(fontext)\n",
      "        Return a list of file extensions that are synonyms for\n",
      "        the given file extension *fileext*.\n",
      "    \n",
      "    is_opentype_cff_font(filename)\n",
      "        Return whether the given font is a Postscript Compact Font Format Font\n",
      "        embedded in an OpenType wrapper.  Used by the PostScript and PDF backends\n",
      "        that can not subset these fonts.\n",
      "    \n",
      "    json_dump(data, filename)\n",
      "        Dump `FontManager` *data* as JSON to the file named *filename*.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        json_load\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        File paths that are children of the Matplotlib data path (typically, fonts\n",
      "        shipped with Matplotlib) are stored relative to that data path (to remain\n",
      "        valid across virtualenvs).\n",
      "        \n",
      "        This function temporarily locks the output file to prevent multiple\n",
      "        processes from overwriting one another's output.\n",
      "    \n",
      "    json_load(filename)\n",
      "        Load a `FontManager` from the JSON file named *filename*.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        json_dump\n",
      "    \n",
      "    list_fonts(directory, extensions)\n",
      "        Return a list of all fonts matching any of the extensions, found\n",
      "        recursively under the directory.\n",
      "    \n",
      "    ttfFontProperty(font)\n",
      "        Extract information from a TrueType font file.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        font : `.FT2Font`\n",
      "            The TrueType font file from which information will be extracted.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        `FontEntry`\n",
      "            The extracted font properties.\n",
      "    \n",
      "    win32FontDirectory()\n",
      "        Return the user-specified font directory for Win32.  This is\n",
      "        looked up from the registry key ::\n",
      "        \n",
      "          \\\\HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders\\Fonts\n",
      "        \n",
      "        If the key is not found, ``%WINDIR%\\Fonts`` will be returned.\n",
      "\n",
      "DATA\n",
      "    MSFolders = r'Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell...\n",
      "    MSFontDirectories = [r'SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Fo...\n",
      "    MSUserFontDirectories = ['/home/stefanotroffa/AppData/Local/Microsoft/...\n",
      "    OSXFontDirectories = ['/Library/Fonts/', '/Network/Library/Fonts/', '/...\n",
      "    X11FontDirectories = ['/usr/X11R6/lib/X11/fonts/TTF/', '/usr/X11/lib/X...\n",
      "    fontManager = <matplotlib.font_manager.FontManager object>\n",
      "    font_family_aliases = {'cursive', 'fantasy', 'monospace', 'sans', 'san...\n",
      "    font_scalings = {'xx-small': 0.579, 'x-small': 0.694, 'small': 0.833, ...\n",
      "    stretch_dict = {'condensed': 300, 'expanded': 700, 'extended': 700, 'e...\n",
      "    weight_dict = {'black': 900, 'bold': 700, 'book': 400, 'demi': 600, 'd...\n",
      "\n",
      "FILE\n",
      "    /home/stefanotroffa/miniconda3/envs/TFQUANTUM/lib/python3.9/site-packages/matplotlib/font_manager.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager\n",
    "help(matplotlib.font_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:50.317059Z",
     "iopub.status.busy": "2023-03-21T11:34:50.316407Z",
     "iopub.status.idle": "2023-03-21T11:34:50.359258Z",
     "shell.execute_reply": "2023-03-21T11:34:50.358605Z"
    },
    "id": "w3POmUEUojhe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f917a112e50>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(x_train_circ[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEQMxCcBojhg"
   },
   "source": [
    "Compare this circuit to the indices where the image value exceeds the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:50.362398Z",
     "iopub.status.busy": "2023-03-21T11:34:50.361823Z",
     "iopub.status.idle": "2023-03-21T11:34:50.367004Z",
     "shell.execute_reply": "2023-03-21T11:34:50.366356Z"
    },
    "id": "TBIsiXdtojhh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [3, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_img = x_train_bin[0,:,:,0]\n",
    "indices = np.array(np.where(bin_img)).T\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWZ24w1Oojhk"
   },
   "source": [
    "Convert these `Cirq` circuits to tensors for `tfq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:50.370120Z",
     "iopub.status.busy": "2023-03-21T11:34:50.369582Z",
     "iopub.status.idle": "2023-03-21T11:34:55.924172Z",
     "shell.execute_reply": "2023-03-21T11:34:55.923321Z"
    },
    "id": "IZStEMk4ojhk"
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. Quantum neural network\n",
    "\n",
    "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block contains a method to extract an adjacency matrix from the pixel values in the reshape image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10338\n",
      "<class 'scipy.sparse._coo.coo_matrix'>\n",
      "(10338, 16, 16) <class 'numpy.ndarray'>\n",
      "16 (16, 16)\n",
      "(1968, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import feature_extraction\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "\n",
    "#help(sklearn)\n",
    "end=len(x_train_bin)\n",
    "\n",
    "adj_train=[sklearn.feature_extraction.image.img_to_graph(x) for x in x_train_bin[:end]]\n",
    "adj_test =[sklearn.feature_extraction.image.img_to_graph(x) for x in x_test_bin[:len(x_test_bin)]]\n",
    "adj_arrays=vstack(adj_train).toarray()\n",
    "adj_new_test= vstack(adj_test).toarray().reshape(len(x_test_bin), rescale_l**2, rescale_l**2)\n",
    "print(len(adj_train))\n",
    "print(type(adj_train[0]))\n",
    "#print(adj_arrays.reshape(end, rescale_l**2, rescale_l**2))\n",
    "adj_new= adj_arrays.reshape(end, rescale_l**2, rescale_l**2)\n",
    "print(adj_new.shape,type(adj_new))\n",
    "print(len(adj_new[2]), adj_new[2].shape)\n",
    "print(adj_new_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In the following block we encoded the input by forcing the graph structure in the circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_graph(image,adj_new,index):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(rescale_l, rescale_l)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "            \n",
    "    for qubit in range(rescale_l**2):\n",
    "        circuit.append(cirq.H(qubits[qubit]))     \n",
    "        \n",
    "    for row in range(len(adj_new[index])):\n",
    "        for col in range(row):\n",
    "            if adj_new[index][row][col]>0:\n",
    "                rot= np.pi/8\n",
    "                rot=float(rot)\n",
    "                circuit.append(cirq.ZZ(qubits[row], qubits[col])**rot)\n",
    "    values = np.ndarray.flatten(image)\n",
    "    \n",
    "    for qubit in range(rescale_l**2):\n",
    "        # Hadamard gate on wire qubit\n",
    "        circuit.append(cirq.H(qubits[qubit]))\n",
    "\n",
    "    for row in range(len(adj_new[index])):\n",
    "        for col in range(row):\n",
    "            if adj_new[index][row][col] > 0:\n",
    "                rot= np.pi/8\n",
    "                rot=float(rot)\n",
    "\n",
    "                # IsingZZ gate on wires row and col\n",
    "                circuit.append(cirq.ZZ(qubits[row], qubits[col])**rot)\n",
    "   \n",
    "    for qubit in range(rescale_l**2):\n",
    "        # Hadamard gate on wire qubit\n",
    "        circuit.append(cirq.H(qubits[qubit]))\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "x_test_circ_g=[]  \n",
    "for x in x_test_bin:\n",
    "    #print(index)\n",
    "    x_test_circ_g.append(convert_to_graph(x,adj_new_test, index))\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfcirc_g = tfq.convert_to_tensor(x_test_circ_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "x_train_circ_g=[]  \n",
    "for x in x_train_bin:\n",
    "    #print(index)\n",
    "    x_train_circ_g.append(convert_to_graph(x,adj_new, index))\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968 1968\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_circ_g), len(x_test_circ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10338 10338\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_circ_g), len(x_train_circ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfcirc_g = tfq.convert_to_tensor(x_train_circ_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "(0, 0): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(0, 1): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(0, 2): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(0, 3): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(1, 0): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(1, 1): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "(1, 2): â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                    â”‚                                                                            â”‚\n",
      "(1, 3): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                    â”‚                                                                            â”‚\n",
      "(2, 0): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                    â”‚                                                                            â”‚\n",
      "(2, 1): â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                    â”‚            â”‚                   â”‚                                           â”‚          â”‚                   â”‚\n",
      "(2, 2): â”€â”€â”€Xâ”€â”€â”€Hâ”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€ZZ^0.393â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                                             â”‚       â”‚                    â”‚                                             â”‚       â”‚                    â”‚\n",
      "(2, 3): â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                                                     â”‚                    â”‚                                                     â”‚                    â”‚\n",
      "(3, 0): â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                                                     â”‚            â”‚       â”‚                                                     â”‚            â”‚       â”‚\n",
      "(3, 1): â”€â”€â”€Xâ”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€â”€ZZ^0.393â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€â”€ZZ^0.393â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZâ”€â”€â”€â”€â”€â”€â”€â”€â”€Hâ”€â”€â”€\n",
      "                                                                          â”‚           â”‚                                                              â”‚           â”‚\n",
      "(3, 2): â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€ZZ^0.393â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ZZ^0.393â”€â”€â”€â”€ZZ^0.393â”€â”€â”€Hâ”€â”€â”€\n",
      "\n",
      "(3, 3): â”€â”€â”€Hâ”€â”€â”€Hâ”€â”€â”€â”€Hâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "print(x_train_circ_g[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knIzawEeojho"
   },
   "source": [
    "### 2.1 Build the model circuit\n",
    "\n",
    "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
    "\n",
    "Start with a simple class that will add a layer of these gates to a circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:55.928697Z",
     "iopub.status.busy": "2023-03-21T11:34:55.928012Z",
     "iopub.status.idle": "2023-03-21T11:34:55.932882Z",
     "shell.execute_reply": "2023-03-21T11:34:55.932236Z"
    },
    "id": "-hjxxgU5ojho"
   },
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder_graph():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            \n",
    "            circuit.append(cirq.H(qubit))  \n",
    "            \n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            \n",
    "            circuit.append(cirq.H(qubit))  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjo5hANFojhr"
   },
   "source": [
    "Build an example circuit layer to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:55.935947Z",
     "iopub.status.busy": "2023-03-21T11:34:55.935423Z",
     "iopub.status.idle": "2023-03-21T11:34:56.068217Z",
     "shell.execute_reply": "2023-03-21T11:34:56.067561Z"
    },
    "id": "SzXWOpUGojhs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f917c22ba00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
    "                                   readout=cirq.GridQubit(-1,-1))\n",
    "\n",
    "circuit = cirq.Circuit()\n",
    "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n",
      "findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"762.59953125\" height=\"290.0\"><line x1=\"39.810625\" x2=\"732.59953125\" y1=\"45.0\" y2=\"45.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"732.59953125\" y1=\"95.0\" y2=\"95.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"732.59953125\" y1=\"145.0\" y2=\"145.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"732.59953125\" y1=\"195.0\" y2=\"195.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"732.59953125\" y1=\"245.0\" y2=\"245.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"521.8549609375\" x2=\"652.59953125\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"521.8549609375\" x2=\"652.59953125\" y1=\"285.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"381.11039062500004\" x2=\"511.85496093750004\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"381.11039062500004\" x2=\"511.85496093750004\" y1=\"285.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"240.36582031250003\" x2=\"371.11039062500004\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"240.36582031250003\" x2=\"371.11039062500004\" y1=\"285.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"189.99353515625\" x2=\"189.99353515625\" y1=\"45.0\" y2=\"95.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"280.73810546875006\" x2=\"280.73810546875006\" y1=\"45.0\" y2=\"145.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"421.48267578125007\" x2=\"421.48267578125007\" y1=\"45.0\" y2=\"195.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"562.22724609375\" x2=\"562.22724609375\" y1=\"45.0\" y2=\"245.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"521.8549609375\" x2=\"521.8549609375\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"652.59953125\" x2=\"652.59953125\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"521.8549609375\" x2=\"521.8549609375\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"652.59953125\" x2=\"652.59953125\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"381.11039062500004\" x2=\"381.11039062500004\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"511.85496093750004\" x2=\"511.85496093750004\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"381.11039062500004\" x2=\"381.11039062500004\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"511.85496093750004\" x2=\"511.85496093750004\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"240.36582031250003\" x2=\"240.36582031250003\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"371.11039062500004\" x2=\"371.11039062500004\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"240.36582031250003\" x2=\"240.36582031250003\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"371.11039062500004\" x2=\"371.11039062500004\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"25.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"75.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"125.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"175.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"225.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"75.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"89.62125\" y=\"125.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"89.62125\" y=\"175.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"89.62125\" y=\"225.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"149.62125\" y=\"75.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"189.99353515625\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"149.62125\" y=\"25.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"189.99353515625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"240.36582031250006\" y=\"125.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"280.73810546875006\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"240.36582031250006\" y=\"25.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"280.73810546875006\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"321.11039062500004\" y=\"75.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"341.11039062500004\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"381.11039062500004\" y=\"175.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"421.48267578125007\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"381.11039062500004\" y=\"25.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"421.48267578125007\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"461.85496093750004\" y=\"125.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"481.85496093750004\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"521.8549609375\" y=\"225.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"562.22724609375\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"521.8549609375\" y=\"25.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"562.22724609375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"602.59953125\" y=\"175.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"622.59953125\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"672.59953125\" y=\"225.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"692.59953125\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f917c22b430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_builder = CircuitLayerBuilder_graph(data_qubits = cirq.GridQubit.rect(4,1),\n",
    "                                   readout=cirq.GridQubit(-1,-1))\n",
    "\n",
    "circuit = cirq.Circuit()\n",
    "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-QhPE1pojhu"
   },
   "source": [
    "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:56.071509Z",
     "iopub.status.busy": "2023-03-21T11:34:56.071014Z",
     "iopub.status.idle": "2023-03-21T11:34:56.076185Z",
     "shell.execute_reply": "2023-03-21T11:34:56.075517Z"
    },
    "id": "JiALbpwRGL69"
   },
   "outputs": [],
   "source": [
    "def create_quantum_model():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "    \n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    #builder.add_layer(circuit, cirq.ZZ, \"zz2\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_model_g():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    #The standard procedure was CircuitLayerBuilder, it has not the adj matrix encoded and a different structure\n",
    "    builder = CircuitLayerBuilder_graph(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "    \n",
    "    # Then add layers (experiment by adding more).\n",
    "    #builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz2\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:56.079094Z",
     "iopub.status.busy": "2023-03-21T11:34:56.078556Z",
     "iopub.status.idle": "2023-03-21T11:34:56.092611Z",
     "shell.execute_reply": "2023-03-21T11:34:56.091960Z"
    },
    "id": "2QZvVh7vojhx"
   },
   "outputs": [],
   "source": [
    "model_circuit, model_readout = create_quantum_model()\n",
    "model_circuit_g, model_readout = create_quantum_model_g()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
    "\n",
    "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
    "\n",
    "To classify these images, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> prwe use the expectation of a readout qubit in a parameterized circuit. This returns a value between 1 and -1 that can be trivially associated with a binary classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:56.095614Z",
     "iopub.status.busy": "2023-03-21T11:34:56.095078Z",
     "iopub.status.idle": "2023-03-21T11:34:57.350875Z",
     "shell.execute_reply": "2023-03-21T11:34:57.350074Z"
    },
    "id": "ZYdf_KOxojh0"
   },
   "outputs": [],
   "source": [
    "# Build the Keras model.\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    tfq.layers.PQC(model_circuit, model_readout),\n",
    "])\n",
    "model_g = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    tfq.layers.PQC(model_circuit_g, model_readout),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz-FbVc9ojh3"
   },
   "source": [
    "Next, describe the training procedure to the model, using the `compile` method.\n",
    "\n",
    "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit. \n",
    "\n",
    "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
    "\n",
    "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.354489Z",
     "iopub.status.busy": "2023-03-21T11:34:57.354227Z",
     "iopub.status.idle": "2023-03-21T11:34:57.358167Z",
     "shell.execute_reply": "2023-03-21T11:34:57.357437Z"
    },
    "id": "CgMNkC1Fojh5"
   },
   "outputs": [],
   "source": [
    "y_train_hinge = 2.0*y_train_nocon-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nwnveDiojh7"
   },
   "source": [
    "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument. \n",
    "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.361143Z",
     "iopub.status.busy": "2023-03-21T11:34:57.360647Z",
     "iopub.status.idle": "2023-03-21T11:34:57.364606Z",
     "shell.execute_reply": "2023-03-21T11:34:57.363955Z"
    },
    "id": "3XKtZ_TEojh8"
   },
   "outputs": [],
   "source": [
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.367616Z",
     "iopub.status.busy": "2023-03-21T11:34:57.367067Z",
     "iopub.status.idle": "2023-03-21T11:34:57.378148Z",
     "shell.execute_reply": "2023-03-21T11:34:57.377472Z"
    },
    "id": "FlpETlLRojiA"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])\n",
    "model_g.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.380936Z",
     "iopub.status.busy": "2023-03-21T11:34:57.380446Z",
     "iopub.status.idle": "2023-03-21T11:34:57.384656Z",
     "shell.execute_reply": "2023-03-21T11:34:57.383981Z"
    },
    "id": "jkHq2RstojiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pqc (PQC)                   (None, 1)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pqc_1 (PQC)                 (None, 1)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_g.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "### Train the quantum model\n",
    "\n",
    "Training the model takes about 15 min on a Ryzen 4800H cpu, OS: Ubuntu 20.04 on WSL2. (Was not able to configure GPU training yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.387597Z",
     "iopub.status.busy": "2023-03-21T11:34:57.387081Z",
     "iopub.status.idle": "2023-03-21T11:34:57.390441Z",
     "shell.execute_reply": "2023-03-21T11:34:57.389772Z"
    },
    "id": "n8vuQpSLlBV2"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_EXAMPLES = len(x_train_tfcirc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.393215Z",
     "iopub.status.busy": "2023-03-21T11:34:57.392817Z",
     "iopub.status.idle": "2023-03-21T11:34:57.396468Z",
     "shell.execute_reply": "2023-03-21T11:34:57.395818Z"
    },
    "id": "qJnNG-3JojiI"
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc_sub_g = x_train_tfcirc_g[:NUM_EXAMPLES]\n",
    "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
    "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "Training this model to convergence should achieve >85% accuracy on the test set, this refers to not using the graph encoded as input. \n",
    "\n",
    "##### Memo: look into data_reuploading afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:34:57.399510Z",
     "iopub.status.busy": "2023-03-21T11:34:57.398999Z",
     "iopub.status.idle": "2023-03-21T11:38:11.850634Z",
     "shell.execute_reply": "2023-03-21T11:38:11.849803Z"
    },
    "id": "Ya9qP3KkojiM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "324/324 [==============================] - 216s 667ms/step - loss: 0.4119 - hinge_accuracy: 0.8538 - val_loss: 0.3632 - val_hinge_accuracy: 0.8836\n",
      "Epoch 2/3\n",
      "324/324 [==============================] - 217s 671ms/step - loss: 0.3801 - hinge_accuracy: 0.8608 - val_loss: 0.3550 - val_hinge_accuracy: 0.8599\n",
      "Epoch 3/3\n",
      "324/324 [==============================] - 215s 664ms/step - loss: 0.3725 - hinge_accuracy: 0.8655 - val_loss: 0.3491 - val_hinge_accuracy: 0.8594\n",
      "62/62 [==============================] - 6s 90ms/step - loss: 0.3491 - hinge_accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "qnn_history = model.fit(\n",
    "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "      batch_size=32,\n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the following model takes around 20minutes instead. We are encoding the graph structure this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "324/324 [==============================] - 384s 1s/step - loss: 0.8780 - hinge_accuracy: 0.6852 - val_loss: 0.7347 - val_hinge_accuracy: 0.8478\n",
      "Epoch 2/3\n",
      "324/324 [==============================] - 381s 1s/step - loss: 0.6907 - hinge_accuracy: 0.8651 - val_loss: 0.6447 - val_hinge_accuracy: 0.8987\n",
      "Epoch 3/3\n",
      "324/324 [==============================] - 373s 1s/step - loss: 0.6634 - hinge_accuracy: 0.8695 - val_loss: 0.6584 - val_hinge_accuracy: 0.8972\n",
      "62/62 [==============================] - 8s 125ms/step - loss: 1.0000 - hinge_accuracy: 0.6321\n"
     ]
    }
   ],
   "source": [
    "qnn_history_g = model_g.fit(\n",
    "      x_train_tfcirc_sub_g, y_train_hinge_sub,\n",
    "      batch_size=32,\n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test_tfcirc_g, y_test_hinge))\n",
    "\n",
    "qnn_results_g = model.evaluate(x_test_tfcirc_g, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 9s 150ms/step - loss: 0.6584 - hinge_accuracy: 0.8972\n",
      "324/324 [==============================] - 362s 1s/step - loss: 0.6640 - hinge_accuracy: 0.8644 - val_loss: 0.6565 - val_hinge_accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "qnn_results_g = model_g.evaluate(x_test_tfcirc_g, y_test_hinge)\n",
    "qnn_history_g = model_g.fit(\n",
    "      x_train_tfcirc_sub_g, y_train_hinge_sub,\n",
    "      batch_size=32,\n",
    "      epochs=1,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test_tfcirc_g, y_test_hinge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ER7B7aaojiP"
   },
   "source": [
    "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:38:11.854650Z",
     "iopub.status.busy": "2023-03-21T11:38:11.854056Z",
     "iopub.status.idle": "2023-03-21T11:38:11.915983Z",
     "shell.execute_reply": "2023-03-21T11:38:11.915281Z"
    },
    "id": "pZofEHhLGL7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,721\n",
      "Trainable params: 1,198,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:38:11.919274Z",
     "iopub.status.busy": "2023-03-21T11:38:11.918677Z",
     "iopub.status.idle": "2023-03-21T11:38:15.631175Z",
     "shell.execute_reply": "2023-03-21T11:38:15.630430Z"
    },
    "id": "CiAJl7sZojiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 7s 68ms/step - loss: 0.0390 - accuracy: 0.9841 - val_loss: 0.0039 - val_accuracy: 0.9980\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5-5BVJaojiZ"
   },
   "source": [
    "The above model has nearly 1.2M parameters, and trains on the full image. For a fair comparison, consider a smaller Neural network, a 37-parameter model, on the subsampled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:38:15.634858Z",
     "iopub.status.busy": "2023-03-21T11:38:15.634296Z",
     "iopub.status.idle": "2023-03-21T11:38:15.663745Z",
     "shell.execute_reply": "2023-03-21T11:38:15.663076Z"
    },
    "id": "70TOM6r-ojiZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_fair_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_fair_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:38:15.666842Z",
     "iopub.status.busy": "2023-03-21T11:38:15.666248Z",
     "iopub.status.idle": "2023-03-21T11:38:18.278954Z",
     "shell.execute_reply": "2023-03-21T11:38:18.278213Z"
    },
    "id": "lA_Fx-8gojid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 - 0s - loss: 0.6706 - accuracy: 0.5426 - val_loss: 0.6193 - val_accuracy: 0.5706 - 480ms/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "81/81 - 0s - loss: 0.5435 - accuracy: 0.7298 - val_loss: 0.4484 - val_accuracy: 0.8064 - 151ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "81/81 - 0s - loss: 0.3609 - accuracy: 0.8401 - val_loss: 0.2985 - val_accuracy: 0.8623 - 151ms/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "81/81 - 0s - loss: 0.2714 - accuracy: 0.8716 - val_loss: 0.2495 - val_accuracy: 0.8653 - 153ms/epoch - 2ms/step\n",
      "Epoch 5/20\n",
      "81/81 - 0s - loss: 0.2425 - accuracy: 0.8874 - val_loss: 0.2327 - val_accuracy: 0.8653 - 154ms/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "81/81 - 0s - loss: 0.2311 - accuracy: 0.8987 - val_loss: 0.2243 - val_accuracy: 0.9141 - 151ms/epoch - 2ms/step\n",
      "Epoch 7/20\n",
      "81/81 - 0s - loss: 0.2256 - accuracy: 0.9016 - val_loss: 0.2204 - val_accuracy: 0.9141 - 152ms/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "81/81 - 0s - loss: 0.2225 - accuracy: 0.9033 - val_loss: 0.2182 - val_accuracy: 0.9141 - 148ms/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "81/81 - 0s - loss: 0.2208 - accuracy: 0.9038 - val_loss: 0.2169 - val_accuracy: 0.9151 - 151ms/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "81/81 - 0s - loss: 0.2200 - accuracy: 0.9039 - val_loss: 0.2171 - val_accuracy: 0.9162 - 152ms/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "81/81 - 0s - loss: 0.2189 - accuracy: 0.9045 - val_loss: 0.2167 - val_accuracy: 0.9167 - 148ms/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "81/81 - 0s - loss: 0.2182 - accuracy: 0.9046 - val_loss: 0.2160 - val_accuracy: 0.9167 - 155ms/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "81/81 - 0s - loss: 0.2178 - accuracy: 0.9046 - val_loss: 0.2156 - val_accuracy: 0.9167 - 162ms/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "81/81 - 0s - loss: 0.2174 - accuracy: 0.9046 - val_loss: 0.2154 - val_accuracy: 0.9167 - 162ms/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "81/81 - 0s - loss: 0.2171 - accuracy: 0.9052 - val_loss: 0.2158 - val_accuracy: 0.9167 - 162ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "81/81 - 0s - loss: 0.2168 - accuracy: 0.9054 - val_loss: 0.2159 - val_accuracy: 0.9167 - 150ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "81/81 - 0s - loss: 0.2168 - accuracy: 0.9054 - val_loss: 0.2152 - val_accuracy: 0.9167 - 149ms/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "81/81 - 0s - loss: 0.2165 - accuracy: 0.9054 - val_loss: 0.2149 - val_accuracy: 0.9167 - 164ms/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "81/81 - 0s - loss: 0.2162 - accuracy: 0.9054 - val_loss: 0.2154 - val_accuracy: 0.9167 - 156ms/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "81/81 - 0s - loss: 0.2160 - accuracy: 0.9025 - val_loss: 0.2141 - val_accuracy: 0.9167 - 142ms/epoch - 2ms/step\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_bin,\n",
    "          y_train_nocon,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2023-03-21T11:38:18.282725Z",
     "iopub.status.busy": "2023-03-21T11:38:18.282071Z",
     "iopub.status.idle": "2023-03-21T11:38:18.418457Z",
     "shell.execute_reply": "2023-03-21T11:38:18.417721Z"
    },
    "id": "NOMeN7pMGL7P"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "fair_nn_accuracy = fair_nn_results[1]\n",
    "qnn_accuracy_g  = qnn_results_g[1]\n",
    "\n",
    "sns.barplot(x=[\"Quantum\", \"Quantum g\", \"Classical, fair\", \"Classical, full\"],\n",
    "            y=[qnn_accuracy,qnn_accuracy_g , fair_nn_accuracy, cnn_accuracy])\n",
    "plt.title(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TFQUANTUM",
   "language": "python",
   "name": "tfquantum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
